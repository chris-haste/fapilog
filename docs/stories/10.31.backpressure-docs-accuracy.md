# Story 10.31: Backpressure Documentation Accuracy

**Status:** Ready
**Priority:** Medium
**Depends on:** None

---

## Context / Background

An external audit (GPT-5.2 assessment, 2026-01-27) identified a documentation mismatch regarding backpressure policies:

### The Problem

Documentation in `docs/why-fapilog.md` claims three backpressure policies exist:

```markdown
- **drop** - Discard new logs when queue is full (protect latency)
- **wait** - Block until queue has space (protect durability)
- **discard_oldest** - Drop oldest logs to make room (balance both)
```

And shows this example:
```python
logger = (
    LoggerBuilder()
    .with_backpressure(policy="wait")  # Never lose logs
    .build()
)
```

However, the actual `LoggerBuilder.with_backpressure()` API is:

```python
# src/fapilog/builder.py:683-701
def with_backpressure(
    self,
    *,
    wait_ms: int = 50,
    drop_on_full: bool = True,
) -> LoggerBuilder:
```

**Issues:**
1. `policy="wait"` parameter doesn't exist
2. `discard_oldest` policy is not implemented
3. Users will get errors trying to use documented examples

---

## Scope (In / Out)

### In Scope

- Update `docs/why-fapilog.md` to reflect actual API
- Review all docs for backpressure-related accuracy
- Update code examples to use correct API
- Add clarifying comments about what each parameter does

### Out of Scope

- Implementing `discard_oldest` policy (separate story if desired)
- Changing the existing backpressure API
- Adding a `policy` parameter to match old docs

---

## Acceptance Criteria

### AC1: Why-fapilog docs use correct API

**Description:** The backpressure section in `docs/why-fapilog.md` shows the actual API.

**Validation:**
```python
# This example from docs must work without modification
from fapilog import LoggerBuilder

logger = (
    LoggerBuilder()
    .with_backpressure(wait_ms=100, drop_on_full=False)  # Never lose logs
    .build()
)
```

### AC2: Remove references to discard_oldest

**Description:** All docs remove mentions of `discard_oldest` policy since it's not implemented.

**Validation:**
```bash
# Should return no matches
grep -r "discard_oldest" docs/
```

### AC3: Backpressure behavior clearly documented

**Description:** Docs clearly explain what `wait_ms` and `drop_on_full` do and how they combine.

**Validation:**
- `wait_ms=0, drop_on_full=True` → immediate drop if queue full
- `wait_ms=50, drop_on_full=True` → wait up to 50ms, then drop
- `wait_ms=0, drop_on_full=False` → block indefinitely (wait forever)
- `wait_ms=50, drop_on_full=False` → wait 50ms, then block indefinitely

---

## Implementation Notes

### File Changes

```
docs/why-fapilog.md (MODIFIED - fix backpressure section)
docs/user-guide/configuration.md (VERIFY - check for similar issues)
docs/user-guide/reliability-defaults.md (VERIFY - check backpressure docs)
```

### Corrected Documentation

```markdown
## 2. Backpressure Handling

What happens when logs arrive faster than they can be written? Most libraries
either block (hurting latency) or silently drop logs (hurting reliability).
Fapilog lets you configure the tradeoff:

```python
from fapilog import LoggerBuilder

# Protect latency: wait briefly, then drop if still full
logger = (
    LoggerBuilder()
    .with_backpressure(wait_ms=50, drop_on_full=True)
    .build()
)

# Protect durability: never lose logs (may block longer)
logger = (
    LoggerBuilder()
    .with_backpressure(wait_ms=0, drop_on_full=False)
    .build()
)
```

| Configuration | Behavior |
|--------------|----------|
| `wait_ms=50, drop_on_full=True` | Wait up to 50ms for space, then drop (default) |
| `wait_ms=0, drop_on_full=True` | Drop immediately if queue full |
| `wait_ms=0, drop_on_full=False` | Block indefinitely until space available |
| `wait_ms=100, drop_on_full=False` | Wait 100ms, then block indefinitely |
```

---

## Tasks

### Phase 1: Audit Existing Docs

- [ ] Search all docs for "backpressure" mentions
- [ ] Search all docs for "discard_oldest" mentions
- [ ] Search all docs for `policy=` in backpressure context
- [ ] List all files needing updates

### Phase 2: Fix Documentation

- [ ] Update `docs/why-fapilog.md` backpressure section
- [ ] Update any other files found in Phase 1
- [ ] Verify all code examples actually work

### Phase 3: Validation

- [ ] Run doc-accuracy check script
- [ ] Build docs with warnings-as-errors
- [ ] Update CHANGELOG

---

## Tests

### Validation Scripts

- Run `python scripts/check_doc_accuracy.py` to catch code/doc drift
- Run `sphinx-build -W` to catch doc build issues

### Manual Verification

- Copy each code example from updated docs
- Paste into Python REPL
- Verify no errors

---

## Definition of Done

### Code Complete

- [ ] All documentation files updated
- [ ] No references to non-existent features

### Quality Assurance

- [ ] Doc accuracy script passes
- [ ] Sphinx build passes with warnings-as-errors
- [ ] All code examples tested manually

### Documentation

- [ ] CHANGELOG updated

---

## Risks / Rollback

### Risks

1. **Risk:** Users may have workflows expecting `policy=` parameter
   - **Mitigation:** This parameter never existed in code, so no user code would work with it

### Rollback Plan

If issues occur:
1. Git revert the docs changes

---

## Related Stories

- **Related:** Story 10.27 - Builder API parity enforcement (prevents future drift)

---

## Change Log

| Date | Change | Author |
|------|--------|--------|
| 2026-01-27 | Initial draft from audit findings | Claude |
