# Story 11.2: Fix Flaky Test Root Causes

**Status:** Draft
**Priority:** Critical
**Depends on:** None

---

## Context / Background

Ten tests are marked `@pytest.mark.flaky` due to timing-dependent behavior. The CI runs these with `continue-on-error: true`, which prevents build failures but doesn't fix the underlying issues.

**Current flaky tests:**

| File | Line | Test | Root Cause |
|------|------|------|------------|
| `test_logger_threading.py` | 164 | `test_drain_under_backpressure_drops_excess` | Race condition |
| `test_logger_threading.py` | 265 | `test_queue_full_drops_from_cross_thread_submission` | Race condition |
| `test_high_performance_lru_cache.py` | 281 | `test_performance_characteristics` | Timing-sensitive |
| `test_high_performance_lru_cache.py` | 529 | (async performance test) | Timing-sensitive |
| `test_loki_sink_unit.py` | 459 | (monkeypatch test) | Monkeypatch timing |
| `test_hanging_prevention.py` | 123 | `test_concurrent_shutdown_robustness` | Race condition |
| `test_rotating_file_sink.py` | 171 | `test_timestamp_collision_suffix_with_datetime_monkeypatch` | Monkeypatch timing |
| `test_container.py` | 546 | `test_component_retrieval_performance` | Timing-sensitive |
| `test_sink_circuit_breaker.py` | 80 | `test_circuit_transitions_to_half_open_after_timeout` | 50ms timeout too tight |

Per project policy (docs/contributing/test-categories.md:27): `@pytest.mark.flaky` requires an issue link and expiry date, and is never allowed on `critical` or `security` tests.

---

## Scope (In / Out)

### In Scope

- Fix or remove all 10 `@pytest.mark.flaky` tests
- For each test, choose one of:
  1. **Fix:** Address root cause (timing, race condition)
  2. **Rewrite:** Replace with deterministic alternative
  3. **Remove:** Delete if test provides no value
- Document fix approach for each test

### Out of Scope

- Adding new tests beyond what's needed to replace removed ones
- Refactoring non-flaky tests
- Performance optimization (just make tests reliable)

---

## Acceptance Criteria

### AC1: Zero Flaky Test Markers

**Description:** No tests in the codebase use `@pytest.mark.flaky`.

**Validation:**
```bash
grep -r "@pytest.mark.flaky" tests/ | grep -v "test_verify_test_markers.py" | wc -l
# Expected: 0
```

### AC2: All Fixed Tests Pass Consistently

**Description:** Each fixed test passes 10 times in a row.

**Validation:**
```bash
pytest tests/unit/test_logger_threading.py::TestBackpressure::test_drain_under_backpressure_drops_excess --count=10
# All 10 should pass
```

### AC3: Race Conditions Eliminated

**Description:** Tests with race conditions use proper synchronization primitives.

**Validation:**
- Threading tests use `threading.Event` for coordination
- Async tests use `asyncio.Event` or `asyncio.Condition`
- No reliance on `time.sleep()` for synchronization

### AC4: Timeout Tests Use CI-Appropriate Values

**Description:** Tests with timing thresholds work on slow CI runners.

**Validation:**
- Circuit breaker timeout increased from 50ms to 200ms+ or uses `CI_TIMEOUT_MULTIPLIER`
- Performance threshold tests use relative comparisons, not absolute timings

---

## Implementation Notes

### Fix Strategy by Test

#### 1. `test_logger_threading.py:164` - Race condition in backpressure

**Problem:** Test checks dropped count before drain completes.

**Fix:** Use `threading.Event` to signal drain completion:
```python
def test_drain_under_backpressure_drops_excess(self):
    drain_complete = threading.Event()
    # ... setup ...

    def on_drain_complete():
        drain_complete.set()

    logger.drain(callback=on_drain_complete)
    assert drain_complete.wait(timeout=5.0)
    assert logger.dropped_count == expected
```

#### 2. `test_logger_threading.py:265` - Cross-thread queue full

**Problem:** Race between submission and queue check.

**Fix:** Use barrier synchronization:
```python
def test_queue_full_drops_from_cross_thread_submission(self):
    barrier = threading.Barrier(num_threads + 1)
    # All threads wait at barrier, then submit simultaneously
```

#### 3-4. `test_high_performance_lru_cache.py:281,529` - Performance timing

**Problem:** Absolute timing thresholds fail on slow runners.

**Fix:** Use relative comparisons or skip on CI:
```python
@pytest.mark.skipif(os.getenv("CI"), reason="Performance test, skip in CI")
def test_performance_characteristics(self):
    ...

# Or use relative comparison:
def test_performance_characteristics(self):
    baseline = measure_baseline()
    actual = measure_operation()
    assert actual < baseline * 2  # Relative, not absolute
```

#### 5. `test_loki_sink_unit.py:459` - Monkeypatch timing

**Problem:** Datetime monkeypatch races with async operations.

**Fix:** Use `freezegun` or ensure monkeypatch applies before any async work starts.

#### 6. `test_hanging_prevention.py:123` - Concurrent shutdown race

**Problem:** Shutdown order non-deterministic.

**Fix:** Use `threading.Event` to coordinate shutdown sequence.

#### 7. `test_rotating_file_sink.py:171` - Datetime monkeypatch

**Problem:** Similar to #5.

**Fix:** Apply monkeypatch in fixture before test starts.

#### 8. `test_container.py:546` - Component retrieval performance

**Problem:** Absolute timing threshold.

**Fix:** Convert to relative comparison or skip in CI.

#### 9. `test_sink_circuit_breaker.py:80` - 50ms timeout too tight

**Problem:** 50ms timeout insufficient for slow CI.

**Fix:** Increase to 200ms or use `CI_TIMEOUT_MULTIPLIER`:
```python
timeout = 0.05 * int(os.getenv("CI_TIMEOUT_MULTIPLIER", "1"))
```

---

## Tasks

### Phase 1: Threading Race Conditions (3 tests)

- [ ] Fix `test_drain_under_backpressure_drops_excess`
- [ ] Fix `test_queue_full_drops_from_cross_thread_submission`
- [ ] Fix `test_concurrent_shutdown_robustness`
- [ ] Remove `@pytest.mark.flaky` from each
- [ ] Verify each passes 10x

### Phase 2: Performance/Timing Tests (4 tests)

- [ ] Fix or skip `test_performance_characteristics` (LRU cache)
- [ ] Fix or skip async performance test (LRU cache)
- [ ] Fix or skip `test_component_retrieval_performance`
- [ ] Fix circuit breaker timeout test
- [ ] Remove `@pytest.mark.flaky` from each
- [ ] Verify each passes 10x

### Phase 3: Monkeypatch Timing (2 tests)

- [ ] Fix `test_timestamp_collision_suffix_with_datetime_monkeypatch`
- [ ] Fix Loki sink monkeypatch test
- [ ] Remove `@pytest.mark.flaky` from each
- [ ] Verify each passes 10x

### Phase 4: Validation

- [ ] Verify zero `@pytest.mark.flaky` in codebase
- [ ] Run full test suite
- [ ] Document fixes in CHANGELOG

---

## Tests

### Stability Verification

For each fixed test, verify stability:
```bash
pytest <test_path>::<test_name> --count=10 -v
```

### Full Suite Regression

```bash
pytest tests/ -m "not slow and not integration" -v
```

---

## Definition of Done

### Code Complete

- [ ] All 10 flaky tests fixed or removed
- [ ] Zero `@pytest.mark.flaky` markers in test code
- [ ] Each fix uses proper synchronization (not sleep-based)

### Quality Assurance

- [ ] Each fixed test passes 10x in a row
- [ ] `ruff check` passes
- [ ] `mypy` passes
- [ ] No regression in existing tests

### Documentation

- [ ] Each fix documented in commit message
- [ ] CHANGELOG updated
- [ ] Consider adding patterns to test guidelines

---

## Risks / Rollback

### Risks

1. **Risk:** Fix introduces new failure mode
   - **Mitigation:** Test 10x before removing flaky marker

2. **Risk:** Removing test loses coverage
   - **Mitigation:** Only remove if test has no value; otherwise rewrite

3. **Risk:** Performance tests inherently non-deterministic
   - **Mitigation:** Use relative comparisons or skip in CI

### Rollback Plan

If issues occur:
1. Re-add `@pytest.mark.flaky` temporarily
2. Open issue to track proper fix
3. Investigate with more CI run data

---

## Related Stories

- **Related:** Story 11.1 - event-based patterns apply here
- **Related:** Story 11.4 - CI timeout multipliers help with timing tests
- **Enables:** Removal of `continue-on-error: true` for flaky tests in CI

---

## Change Log

| Date | Change | Author |
|------|--------|--------|
| 2026-01-14 | Initial draft | Claude |
