# Story 10.29: Async Logger Instance Caching

**Status:** Ready
**Priority:** High
**Depends on:** None

---

## Context / Background

A user reported severe resource exhaustion in production:

> "We ended up with 99% CPU utilization and noticed we had 10K+ AsyncLoggerFacade as async event tasks from get_async_logger. Once they leave scope they must be cleaned up otherwise you leave behind all the loggers."

### Root Cause

Each call to `get_async_logger()` creates a **new** `AsyncLoggerFacade` instance with no caching (`src/fapilog/__init__.py:779-784`). Each facade spawns worker tasks in `start()` that persist until explicitly drained (`src/fapilog/core/logger.py:199-201`).

Without calling `drain()` or `stop_and_drain()`, these worker tasks accumulate indefinitely. In container logging scenarios where `get_async_logger()` is called per-request or per-operation, this leads to:

- Unbounded task accumulation
- Event loop overwhelmed managing thousands of idle worker tasks
- CPU exhaustion and eventual OOM

### How Other Libraries Handle This

Python's standard `logging` module caches loggers by name:

```python
# stdlib behavior - same instance returned for same name
logger1 = logging.getLogger("my-service")
logger2 = logging.getLogger("my-service")
assert logger1 is logger2  # True
```

This is the expected behavior users bring from stdlib, structlog, and loguru. Fapilog should match this pattern.

### Current Workarounds

Users must either:
1. Implement their own singleton pattern
2. Use `runtime_async()` context manager everywhere
3. Manually track and drain all logger instances

None of these are obvious from the API surface.

---

## Scope (In / Out)

### In Scope

- Name-based instance caching for `get_async_logger()` and `get_logger()`
- `reuse` parameter for opting out (tests, isolated configurations)
- `ResourceWarning` in `__del__` for undrained loggers
- Cache management functions (`clear_logger_cache()`)
- Documentation for logger lifecycle

### Out of Scope

- Automatic cleanup via weak references (unreliable with event loops)
- Changes to `runtime_async()` behavior (already correct)
- Changes to `LoggerBuilder` (uses different instantiation pattern)
- Thread-safety improvements beyond basic locking (future story if needed)

---

## Acceptance Criteria

### AC1: Same Name Returns Same Instance

**Description:** Calling `get_async_logger()` or `get_logger()` with the same name returns the same cached instance.

**Validation:**
```python
import asyncio
from fapilog import get_async_logger, get_logger

# Async logger caching
async def test_async_caching():
    logger1 = await get_async_logger("my-service")
    logger2 = await get_async_logger("my-service")
    assert logger1 is logger2

# Sync logger caching
def test_sync_caching():
    logger1 = get_logger("my-service")
    logger2 = get_logger("my-service")
    assert logger1 is logger2

# Default logger (no name) is also cached
async def test_default_cached():
    logger1 = await get_async_logger()
    logger2 = await get_async_logger()
    assert logger1 is logger2
```

### AC2: Reuse Parameter Allows Opt-Out

**Description:** Setting `reuse=False` creates a new instance, useful for tests or isolated configurations.

**Validation:**
```python
async def test_reuse_false():
    logger1 = await get_async_logger("test-logger")
    logger2 = await get_async_logger("test-logger", reuse=False)

    assert logger1 is not logger2  # Different instances

    # Cleanup both
    await logger1.drain()
    await logger2.drain()
```

### AC3: ResourceWarning on Undrained Logger GC

**Description:** When an `AsyncLoggerFacade` with active workers is garbage collected without being drained, a `ResourceWarning` is emitted.

**Validation:**
```python
import warnings

async def test_undrained_warning():
    with warnings.catch_warnings(record=True) as w:
        warnings.simplefilter("always", ResourceWarning)

        # Create logger without caching and don't drain
        logger = await get_async_logger("ephemeral", reuse=False)
        del logger

        # Force GC
        import gc
        gc.collect()

        # Should have emitted ResourceWarning
        assert any("drain()" in str(warning.message) for warning in w)
```

### AC4: Cache Management Functions

**Description:** Provide functions to inspect and clear the logger cache for testing and advanced use cases.

**Validation:**
```python
from fapilog import clear_logger_cache, get_cached_loggers

async def test_cache_management():
    # Create some loggers
    await get_async_logger("service-a")
    await get_async_logger("service-b")

    # Inspect cache
    cached = get_cached_loggers()
    assert "service-a" in cached
    assert "service-b" in cached

    # Clear cache (drains all loggers)
    await clear_logger_cache()

    cached = get_cached_loggers()
    assert len(cached) == 0
```

### AC5: Thread-Safe Cache Access

**Description:** Cache operations are thread-safe for concurrent access patterns.

**Validation:**
```python
import asyncio
import threading

async def test_concurrent_access():
    results = []

    async def get_logger_task():
        logger = await get_async_logger("shared")
        results.append(id(logger))

    # Run 100 concurrent tasks
    await asyncio.gather(*[get_logger_task() for _ in range(100)])

    # All should return the same instance
    assert len(set(results)) == 1
```

### AC6: Documentation Updated

**Description:** Logger lifecycle and caching behavior documented.

**Validation:**
- `docs/user-guide/using-logger.md` mentions caching behavior
- `docs/api-reference/top-level-functions.md` documents `reuse` parameter
- `docs/user-guide/testing-plugins.md` shows `reuse=False` pattern for tests
- Docstrings updated for `get_async_logger()` and `get_logger()`

### AC7: `runtime_async()` Uses Independent Instance

**Description:** The `runtime_async()` context manager must not pollute the cache with a drained logger.

**Validation:**
```python
async def test_runtime_async_does_not_pollute_cache():
    # Use runtime_async - it drains on exit
    async with runtime_async() as logger1:
        await logger1.info("test")

    # Get a new logger with same default name
    logger2 = await get_async_logger()

    # Should be a fresh, working logger (not the drained one)
    await logger2.info("still works")
    assert logger2._worker_tasks  # Has active workers
```

**Implementation options:**
1. `runtime_async()` uses `reuse=False` internally
2. `drain()` removes the logger from cache automatically

---

## Implementation Notes

### File Changes

```
src/fapilog/__init__.py (MODIFIED - add caching logic, update runtime_async)
src/fapilog/core/logger.py (MODIFIED - add __del__ warning)
tests/unit/test_logger_caching.py (NEW - caching tests)
tests/unit/test_logger_resource_warning.py (NEW - ResourceWarning tests)
docs/user-guide/using-logger.md (MODIFIED - document caching)
docs/api-reference/top-level-functions.md (MODIFIED - document reuse param)
docs/user-guide/testing-plugins.md (MODIFIED - show reuse=False pattern)
CHANGELOG.md (MODIFIED - document new feature)
```

### Cache Implementation

```python
# src/fapilog/__init__.py

import threading
from typing import Dict

# Module-level caches with locks for thread safety
_async_logger_cache: Dict[str, _AsyncLoggerFacade] = {}
_sync_logger_cache: Dict[str, _SyncLoggerFacade] = {}
_cache_lock = threading.Lock()

_DEFAULT_LOGGER_KEY = "__fapilog_default__"


async def get_async_logger(
    name: str | None = None,
    *,
    preset: str | None = None,
    format: _Literal["json", "pretty", "auto"] | None = None,
    settings: _Settings | None = None,
    sinks: list[object] | None = None,
    auto_detect: bool = True,
    environment: str | None = None,
    reuse: bool = True,  # NEW PARAMETER
) -> _AsyncLoggerFacade:
    """Return an async logger with optional preset or output format controls.

    Args:
        name: Optional logger name. Loggers with the same name return the same
            cached instance by default (like stdlib logging.getLogger).
        ...existing args...
        reuse: If True (default), return cached instance for this name.
            Set to False to create a new independent instance (useful for tests).

    Note:
        Cached loggers persist for the application lifetime. For short-lived
        scripts, use `runtime_async()` context manager for automatic cleanup.
    """
    cache_key = name or _DEFAULT_LOGGER_KEY

    # Fast path: check cache without lock
    if reuse and cache_key in _async_logger_cache:
        return _async_logger_cache[cache_key]

    # Check if non-default params would create a different config
    # If reuse=True but params differ from cached, warn and return cached
    # (matching stdlib behavior where getLogger ignores config after first call)

    # Slow path: create new logger
    setup, _ = _prepare_logger(
        name,
        preset=preset,
        format=format,
        settings=settings,
        sinks=sinks,
        auto_detect=auto_detect,
        environment=environment,
    )

    enrichers = await _start_plugins(setup.enrichers, "enricher")
    redactors = await _start_plugins(setup.redactors, "redactor")
    processors = await _start_plugins(setup.processors, "processor")
    filters = await _start_plugins(setup.filters, "filter")

    facade = _cast(
        _AsyncLoggerFacade,
        _create_and_start_facade(
            _AsyncLoggerFacade, name, setup, enrichers, redactors, processors, filters
        ),
    )

    if reuse:
        with _cache_lock:
            # Double-check pattern
            if cache_key in _async_logger_cache:
                # Another thread created it, drain ours and return theirs
                await facade.drain()
                return _async_logger_cache[cache_key]
            _async_logger_cache[cache_key] = facade

    return facade


def get_cached_loggers() -> dict[str, str]:
    """Return names of all cached loggers.

    Returns:
        Dict mapping cache keys to logger types ("async" or "sync").
    """
    with _cache_lock:
        result = {}
        for key in _async_logger_cache:
            result[key] = "async"
        for key in _sync_logger_cache:
            result[key] = "sync"
        return result


async def clear_logger_cache() -> None:
    """Drain and remove all cached loggers.

    Useful for test cleanup or application shutdown.
    """
    with _cache_lock:
        async_loggers = list(_async_logger_cache.values())
        sync_loggers = list(_sync_logger_cache.values())
        _async_logger_cache.clear()
        _sync_logger_cache.clear()

    # Drain outside lock to avoid deadlocks
    for logger in async_loggers:
        try:
            await logger.drain()
        except Exception:
            pass

    for logger in sync_loggers:
        try:
            logger.drain()
        except Exception:
            pass
```

### ResourceWarning Implementation

```python
# src/fapilog/core/logger.py

class AsyncLoggerFacade:
    def __init__(self, ...):
        ...
        self._drained: bool = False

    async def drain(self) -> None:
        ...
        self._drained = True

    def __del__(self) -> None:
        """Warn if logger is garbage collected without being drained."""
        # Only warn if we have active workers and weren't drained
        if self._worker_tasks and not self._drained:
            import warnings
            warnings.warn(
                f"AsyncLoggerFacade '{self._name or 'default'}' was garbage "
                "collected without calling drain(). This causes resource leaks. "
                "Use runtime_async() context manager, call drain() explicitly, "
                "or use the default name-based caching (reuse=True).",
                ResourceWarning,
                stacklevel=2,
            )
```

---

## Tasks

### Phase 1: Core Implementation

- [ ] Add `_async_logger_cache`, `_sync_logger_cache`, and `_cache_lock` to `__init__.py`
- [ ] Add `reuse` parameter to `get_async_logger()` with caching logic
- [ ] Add `reuse` parameter to `get_logger()` with caching logic
- [ ] Add `get_cached_loggers()` function
- [ ] Add `clear_logger_cache()` async function
- [ ] Update `runtime_async()` to use `reuse=False` (prevent cache pollution)
- [ ] Export new functions in `__all__`

### Phase 2: ResourceWarning

- [ ] Add `_drained` flag to `AsyncLoggerFacade`
- [ ] Set `_drained = True` in `drain()` and `stop_and_drain()`
- [ ] Add `__del__` method with `ResourceWarning`
- [ ] Add same pattern to `SyncLoggerFacade`

### Phase 3: Testing

- [ ] Create `tests/unit/test_logger_caching.py`
  - Test same name returns same instance
  - Test default logger caching
  - Test `reuse=False` creates new instance
  - Test `get_cached_loggers()` returns correct info
  - Test `clear_logger_cache()` drains all loggers
  - Test concurrent access returns same instance
- [ ] Create `tests/unit/test_logger_resource_warning.py`
  - Test warning emitted on undrained GC
  - Test no warning when properly drained
  - Test no warning for cached loggers (they persist)
- [ ] Update existing tests to use `reuse=False` where isolation is needed

### Phase 4: Documentation

- [ ] Update `get_async_logger()` docstring with caching behavior
- [ ] Update `get_logger()` docstring with caching behavior
- [ ] Add caching section to `docs/user-guide/getting-started.md`
- [ ] Add testing patterns to `docs/user-guide/testing.md`
- [ ] Add CHANGELOG entry

---

## Tests

### Unit Tests

- `tests/unit/test_logger_caching.py`
  - `test_async_logger_same_name_returns_same_instance`
  - `test_async_logger_default_is_cached`
  - `test_async_logger_different_names_different_instances`
  - `test_async_logger_reuse_false_creates_new`
  - `test_sync_logger_same_name_returns_same_instance`
  - `test_get_cached_loggers_returns_all`
  - `test_clear_logger_cache_drains_all`
  - `test_concurrent_access_returns_same_instance`

- `tests/unit/test_logger_resource_warning.py`
  - `test_undrained_async_logger_warns`
  - `test_drained_async_logger_no_warning`
  - `test_undrained_sync_logger_warns`
  - `test_cached_logger_no_warning_on_scope_exit`

- `tests/unit/test_runtime_async.py`
  - `test_runtime_async_does_not_pollute_cache`
  - `test_runtime_async_uses_independent_instance`

### Integration Tests

- `tests/integration/test_logger_lifecycle.py`
  - `test_cached_logger_survives_function_scope`
  - `test_clear_cache_allows_reconfiguration`

---

## Definition of Done

### Code Complete

- [ ] `get_async_logger()` caches by name (default behavior)
- [ ] `get_logger()` caches by name (default behavior)
- [ ] `reuse=False` parameter works for both functions
- [ ] `get_cached_loggers()` implemented and exported
- [ ] `clear_logger_cache()` implemented and exported
- [ ] `runtime_async()` uses `reuse=False` to avoid cache pollution
- [ ] `ResourceWarning` emitted for undrained loggers
- [ ] `_drained` flag tracked correctly

### Quality Assurance

- [ ] Unit tests written and passing
- [ ] `ruff check` passes
- [ ] `ruff format --check` passes
- [ ] `mypy` passes on changed files
- [ ] `diff-cover` >= 90% on changed lines
- [ ] `vulture` passes (no dead code)
- [ ] `python scripts/lint_test_assertions.py tests/` passes
- [ ] No regression in existing tests

### Documentation

- [ ] Docstrings updated for all public functions
- [ ] `docs/user-guide/using-logger.md` mentions caching behavior
- [ ] `docs/user-guide/testing-plugins.md` shows `reuse=False` pattern
- [ ] CHANGELOG entry added

---

## Risks / Rollback

### Risks

1. **Risk:** Cached loggers with different configurations
   - **Mitigation:** First configuration wins (stdlib behavior)
   - **Mitigation:** Document that `reuse=False` allows different configs

2. **Risk:** Memory growth from cached loggers
   - **Mitigation:** Loggers are lightweight; cache is bounded by unique names
   - **Mitigation:** `clear_logger_cache()` provides explicit cleanup

3. **Risk:** Thread-safety issues with cache access
   - **Mitigation:** Use `threading.Lock` for cache modifications
   - **Mitigation:** Fast path reads without lock (dict access is atomic in CPython)

4. **Risk:** `__del__` warnings in interpreter shutdown
   - **Mitigation:** Check if interpreter is finalizing before warning
   - **Mitigation:** Use `sys.is_finalizing()` guard (available since Python 3.6)

### Rollback Plan

If issues occur:
1. Revert caching logic, keeping `reuse` parameter (always `False` behavior)
2. Keep `ResourceWarning` as it's purely informational
3. Update documentation to reflect no caching

---

## Related Stories

- **Related:** Story 10.7 (Fluent Builder API) - alternative logger creation pattern
- **Related:** Story 10.3 (FastAPI Integration) - uses lifespan for cleanup
- **Enables:** Better container/serverless deployments without resource leaks

---

## Change Log

| Date | Change | Author |
|------|--------|--------|
| 2026-01-20 | Initial draft based on user-reported resource leak | Claude |
| 2026-01-20 | Story review: Fixed doc paths, added AC7 for runtime_async cache interaction, fixed sys.is_finalizing version note | Claude |
